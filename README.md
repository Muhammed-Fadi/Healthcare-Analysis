 Healthcare Medical Condition Notebook

Repository contents

healthcare_medical_condition_notebook.ipynb — Jupyter notebook with end-to-end EDA and preprocessing for the healthcare dataset (target: Medical Condition).

healthcare_dataset.csv — Raw CSV dataset (columns listed below).

health_processed_medical_condition.csv (generated by the notebook) — cleaned & processed dataset saved by the notebook.

selected_features_medical_condition.json (optional) — top features saved by the feature-selection step.

README.md — this file.

Project overview

This repository demonstrates a complete Exploratory Data Analysis (EDA) and preprocessing pipeline for a hospital dataset whose goal is to predict the patient's Medical Condition using available admission, demographic, billing and test data.

Primary goals

Clean and standardize the dataset

Feature-engineer useful variables (e.g., length of stay, timestamp features)

Safely encode categorical variables

Select an informative feature subset

Scale and prepare data for machine learning

Provide visualizations for EDA

Target variable: Medical Condition (encoded in the notebook as Medical_Condition_Label)

Dataset columns

The notebook expects a CSV with these columns (present in healthcare_dataset.csv):

Name

Age

Gender

Blood Type

Medical Condition ← target

Date of Admission

Doctor

Hospital

Insurance Provider

Billing Amount

Room Number

Admission Type

Discharge Date

Medication

Test Results

Requirements

Create a Python environment and install dependencies. Example:

python -m venv venv
source venv/bin/activate      # macOS / Linux
# venv\Scripts\activate       # Windows

pip install --upgrade pip
pip install pandas numpy matplotlib scikit-learn jupyterlab
# optional: install seaborn if you want extra plots locally
pip install seaborn


requirements.txt (example) — add to repo if you want reproducible installs:

pandas
numpy
matplotlib
scikit-learn
jupyterlab
seaborn

How to run

Put healthcare_dataset.csv in the repository root (or update the path in the notebook).

Launch Jupyter:

jupyter lab
# or
jupyter notebook


Open healthcare_medical_condition_notebook.ipynb and run cells top → bottom. The notebook is organized for stepwise execution:

Imports & setup

Read CSV and standardize columns

Missing values handling

Duplicate removal

Date parsing & length-of-stay feature

Outlier handling (IQR method — optional)

Visual analysis (several plots)

Skewness & kurtosis inspection

Encoding (label & one-hot / frequency encoding)

Feature selection (SelectKBest + optional RF/MI in extended version)

Scaling and Train/Test split

Saves health_processed_medical_condition.csv to /mnt/data/ (~project root in local runs)

After preprocessing you may add modeling cells (Logistic Regression, RandomForest, XGBoost) to evaluate the selected features.

Example — quick script to load cleaned dataset (Python)
import pandas as pd

df = pd.read_csv('healthcare_dataset.csv')
# quick check
print(df.columns)
print(df.shape)


In the notebook the processed dataset will be saved as:

/mnt/data/health_processed_medical_condition.csv


(You can change the save path in the notebook.)

Notes on sensitive data & privacy

This dataset contains potentially sensitive personal information (e.g., Name, Room Number, Doctor, Hospital, Medical Condition). Before sharing or publishing downstream results:

Remove or hash all PII (Name, Room Number, etc.). The provided notebook already includes an option to drop these fields before modeling.

If working with real patient data, ensure compliance with relevant regulations (HIPAA, GDPR, local law).

Consider aggregation or differential privacy techniques for public release.

Feature selection & modeling tips

The notebook contains a SelectKBest workflow for an initial filter. For more robust selection, consider:

Mutual information (mutual_info_classif) for non-linear relationships

Tree-based feature importance (RandomForest / XGBoost)

Recursive Feature Elimination (RFE)

Permutation importance for stability checking

If the Medical Condition classes are imbalanced, use stratified CV and consider techniques such as class weights, oversampling (SMOTE), or undersampling.

Always evaluate with multiple metrics (precision/recall/F1, ROC-AUC) depending on the use case.
